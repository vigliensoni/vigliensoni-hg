<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>vigliensoni</title><meta name=description content="Website for music artist and researcher Gabriel Vigliensoni."><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://vigliensoni.com/css/bootstrap.min.css><link rel=stylesheet href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic"><link rel=stylesheet href=https://vigliensoni.com/css/font-awesome.min.css><link rel=stylesheet href=https://vigliensoni.com/css/owl.carousel.css><link rel=stylesheet href=https://vigliensoni.com/css/owl.theme.css><link href=https://vigliensoni.com/css/style.default.css rel=stylesheet id=theme-stylesheet><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link href=https://vigliensoni.com/css/custom.css rel=stylesheet><link rel="shortcut icon" href=https://vigliensoni.com/img/favicon.png></head><body><div id=all><div class=container-fluid><div class="row row-offcanvas row-offcanvas-left"><div id=sidebar class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas"><div class=sidebar-content><h1 class=sidebar-heading><a href=https://vigliensoni.com/>vigliensoni</a></h1><p class=sidebar-p>Music artist and researcher.</p><ul class=sidebar-menu><li><a href=https://vigliensoni.com/categories/featured>Home</a></li><li><a href=https://vigliensoni.com/portfolio/>Portfolio</a></li><li><a href=https://vigliensoni.com/categories/music>Music</a></li><li><a href=https://vigliensoni.com/research/>Research</a></li><li><a href=https://vigliensoni.com/categories/presentation/>Workshops & talks</a></li><li><a href=https://vigliensoni.com/about/>About</a></li><li><a href=https://vigliensoni.com/contact/>Contact</a></li></ul><p class=social><a href=/contact/ data-animate-hover=pulse class=email title=E-mail><i class="fa fa-envelope"></i></a>
<a href=https://instagram.com/vigliensoni title class="external instagram" title=Instagram><i class="fa fa-instagram"></i></a>
<a href=https://github.com/vigliensoni data-animate-hover=pulse class=external title=GitHub><i class="fa fa-github"></i></a>
<a href=https://www.youtube.com/@vigliensoni/videos data-animate-hover=pulse class=external title=YouTube><i class="fa fa-youtube"></i></a>
<a href=https://facebook.com/vigliensoni data-animate-hover=pulse class="external facebook" title=Facebook><i class="fa fa-facebook"></i></a></p><div class=copyright><p class=credit>&copy;2022 Gabriel Vigliensoni<br><br>Template by <a href=https://bootstrapious.com/free-templates class=external>Bootstrapious.com</a>
& ported to Hugo by <a href=https://github.com/kishaningithub>Kishan B</a></p></div></div></div><div class="col-xs-12 col-sm-8 col-md-9 content-column white-background"><div class="small-navbar visible-xs"><button type=button data-toggle=offcanvas class="btn btn-ghost pull-left"> <i class="fa fa-align-left"></i>Menu</button><h1 class=small-navbar-heading><a href=https://vigliensoni.com/>vigliensoni</a></h1></div><div class=row><div class=col-lg-8><div class=content-column-content><h1>Real-time control of neural audio synthesis | Ella</h1><div class=tagbox><a id=date href=/years/2022>(2022)</a>&nbsp;
<a href=/tags/live>Live</a>&nbsp; <a href=/tags/research>Research</a></div><br><p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/sGWzJ3-YuuU style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div>In the video I am improvising with sound artist dedosmuertos, in La Villette, Paris. I am interacting in real time with the latent space representation of several models trained on raw audio using the RAVE neural network architecture (Caillon and Esling, 2021). To interact with the latent space, I am using a Gametrak controller. By means of Wekinator (Fiebrink and Cook, 2009), an application for supervised, interactive machine learning, I&rsquo;m mapping the performance space to the latent space representation of the model.</p><p><strong>MOTIVATION</strong></p><p>I am very much interested in new ways of synthesizing and interacting with sound. Recent advances in neural audio synthesis systems, such as OpenAI&rsquo;s Jukebox, Google Magenta&rsquo;s DDSP, and IRCAM&rsquo;s RAVE offer novel ways of generating sound in raw audio form from a model learned from audio directly.</p><p>Among those three architectures, DDSP and RAVE can be steered in real time at inference time, enabling a much wanted control of the sound generation processs.</p><p><strong>DIRECT CONTROL OF THE LATENT SPACE</strong></p><p>DDSP can be conditioned on pitch and level. RAVE can be conditioned on audio signal content (spectral characteristics and level). DDSP was designed to model monophonic sounds. RAVE was conceived to model full audio texture.</p><p><strong>SOUND CORPORA AND NEURAL AUDIO MODELS</strong></p><p>I have been training RAVE in several full audio texture corpora.</p><ul><li>Aventures Sonores (Corpus collected and assembled by sound artist Maar Colasso. It consists of poetry read by friends, conversations and historical recordingss of First Nations from South America, audio documents about space and time. 4.5 hours)</li><li>vigliensoni. (All my music compiled into one corpus. 8h)</li><li>Electro-percussive (Several albums of percussive music made mostly with electronic instruments. 15h)</li><li>Acoustic-percussive (Several albums of percussive music made mostly with acoustic instruments. 19h)</li><li>Electro-harmonic (Several albums of harmonic music made by electronic means. 22h)</li><li>Acoustic-harmonic (Several albums of harmonic music made mostly by acoustic means. 33h)</li><li>Waterlab. (Corpus recorded and assembled by sound artist Maar Colasso. 4h)</li><li>Archivo sonoro Museo de la memoria y derechos humanos (120h)<ul><li>Historical recordings (e.g., discourses, manifestations)</li><li>Music (e.g., from radio shows)</li><li>Audio letters</li></ul></li></ul><p><strong>CONTROLLING GENERATIVE MODELS WITH INTERACTIVE MACHINE LEARNING</strong></p><p><figure><img src=/img/papers/RAVE-IML-mapping.jpg alt="CONTROLLING GENERATIVE MODELS WITH INTERACTIVE MACHINE LEARNING"></figure>An interactive machine learning environment (such as Wekinator), allows to easily map the low-dimensional peformance space to the highly dimensional neural audio model space.</p><p><strong>THOUGHTS</strong></p><ul><li>Small datasets are enough to learn useful models</li><li>Latent space representations can lead to unexpected, surprising places</li><li>Non-linearity allows to find new ways of looking at the creative process</li><li>Recent generative systems can be steered in realtime</li><li>Contemporary AI systems can support musical creativity</li><li>New tools should imply new music</li></ul></div></div></div></div></div></div></div><script src=https://vigliensoni.com/js/jquery.min.js></script>
<script src=https://vigliensoni.com/js/bootstrap.min.js></script>
<script src=https://vigliensoni.com/js/jquery.cookie.js></script><script src=https://vigliensoni.com/js/ekko-lightbox.js></script>
<script src=https://vigliensoni.com/js/jquery.scrollTo.min.js></script>
<script src=https://vigliensoni.com/js/masonry.pkgd.min.js></script>
<script src=https://vigliensoni.com/js/imagesloaded.pkgd.min.js></script>
<script src=https://vigliensoni.com/js/owl.carousel.min.js></script>
<script src=https://vigliensoni.com/js/front.js></script></body></html>