<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>vigliensoni</title><meta name=description content="Website for music artist and researcher Gabriel Vigliensoni."><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://vigliensoni.com/css/bootstrap.min.css><link rel=stylesheet href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic"><link rel=stylesheet href=https://vigliensoni.com/css/font-awesome.min.css><link rel=stylesheet href=https://vigliensoni.com/css/owl.carousel.css><link rel=stylesheet href=https://vigliensoni.com/css/owl.theme.css><link href=https://vigliensoni.com/css/style.default.css rel=stylesheet id=theme-stylesheet><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link href=https://vigliensoni.com/css/custom.css rel=stylesheet><link rel="shortcut icon" href=https://vigliensoni.com/img/favicon.png></head><body><div id=all><div class=container-fluid><div class="row row-offcanvas row-offcanvas-left"><div id=sidebar class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas"><div class=sidebar-content><h1 class=sidebar-heading><a href=https://vigliensoni.com/>vigliensoni</a></h1><p class=sidebar-p>Music artist and researcher.</p><ul class=sidebar-menu><li><a href=https://vigliensoni.com/categories/featured>Home</a></li><li><a href=https://vigliensoni.com/portfolio/>Portfolio</a></li><li><a href=https://vigliensoni.com/categories/music>Music</a></li><li><a href=https://vigliensoni.com/research/>Research</a></li><li><a href=https://vigliensoni.com/categories/presentation/>Workshops & talks</a></li><li><a href=https://vigliensoni.com/about/>About</a></li><li><a href=https://vigliensoni.com/contact/>Contact</a></li></ul><p class=social><a href=/contact/ data-animate-hover=pulse class=email title=E-mail><i class="fa fa-envelope"></i></a>
<a href=https://instagram.com/vigliensoni title class="external instagram" title=Instagram><i class="fa fa-instagram"></i></a>
<a href=https://github.com/vigliensoni data-animate-hover=pulse class=external title=GitHub><i class="fa fa-github"></i></a>
<a href=https://www.youtube.com/@vigliensoni/videos data-animate-hover=pulse class=external title=YouTube><i class="fa fa-youtube"></i></a>
<a href=https://facebook.com/vigliensoni data-animate-hover=pulse class="external facebook" title=Facebook><i class="fa fa-facebook"></i></a></p><div class=copyright><p class=credit>&copy;2022 Gabriel Vigliensoni<br><br>Template by <a href=https://bootstrapious.com/free-templates class=external>Bootstrapious.com</a>
& ported to Hugo by <a href=https://github.com/kishaningithub>Kishan B</a></p></div></div></div><div class="col-xs-12 col-sm-8 col-md-9 content-column white-background"><div class="small-navbar visible-xs"><button type=button data-toggle=offcanvas class="btn btn-ghost pull-left"> <i class="fa fa-align-left"></i>Menu</button><h1 class=small-navbar-heading><a href=https://vigliensoni.com/>vigliensoni</a></h1></div><div class=row><div class=col-lg-8><div class=content-column-content><h1>R-VAE: Live latent space drum rhythm generation from minimal-size datasets</h1><div class=tagbox><a id=date href=/years/2022>(2022)</a>&nbsp;
<a href=/tags/research>Research</a>&nbsp; <a href=/tags/paper>Paper</a></div><br><p>Journal of Creative Music Systems</p><p><a href=https://doi.org/10.5920/jcms.902>Gabriel Vigliensoni, Louis McCallum, Esteban Maestre, and Rebecca Fiebrink. 2022. <em>Journal of Creative Music Systems 1(1).</em></a></p><h3 id=abstract>Abstract</h3><p>In this article, we present R-VAE, a system designed for the modeling and exploration of latent spaces learned from rhythms encoded in MIDI clips. The system is based on a variational autoencoder neural network, uses a data structure that is capable of encoding rhythms in simple and compound meter, and can learn models from little training data. To facilitate the exploration of models, we implemented a visualizer that relies on the dynamic nature of the pulsing rhythmic patterns. To test our system in real-life musical practice, we collected small-scale datasets of contemporary music genre rhythms and trained models with them. We found that the non-linearities of the learned latent spaces coupled with tactile interfaces to interact with the models were very expressive and led to unexpected places in musical composition and live performance settings. A music album was recorded and it was premiered at a major music festival using the VAE latent space on stage.</p><p>MAIN FINDINGS AND CONTRIBUTIONS</p><p><figure><img src=/img/papers/midi-24ppqn-cropped.jpg></figure>Data structure chosen to allocate simple and compound meter rhythms. The
horizontal axis shows all 96 ticks in one 4/4 bar with 24 ppqn (pulses per quarter note)
resolution. The y axis show standard subdivisions, where 4 indicates quarter notes, 8 indicates eight notes, 8T is used for eight triplets, and so on. The maximum resolution is a 32nd triplet note.</p><p>neural architexture figure</p><p>At training time, rhythmic data in symbolic music format is described in terms of their onsets, velocities, and microtimings, and encoded into a latent space. At gen- eration time, a musician samples this space directly using a performance interface. The rhythmic patterns are then retrieved and decoded into a symbolic music format.</p><p>DINAMIC VISUALIZER<figure><img src=/img/papers/diagram-visualizer.jpg></figure>Diagram illustrating the mapping from the latent space to the performance space canvas. On the left, four discrete points (i.e., four rhythms) of the latent space are sampled over time, each represented in the figure as a 3-by-3 matrix. Each instrument in a rhythmic pattern will trigger a specific matrix cell with a single color. On the right, the full performance space, made of 900 points sampled from the latent space, is shown. Here, the visualization shows how the activation of different drum instruments (i.e., kick, snare, and hi-hat) differs across the latent space for this particular moment in time, t. A full measure consists of 96 of these images, played in sequence to produce a dynamic animation.
The user interface of R-VAE-JS web application is displayed on the right. The latent space can be explored by moving the mouse. Additional knobs for threshold and noise, as well as shortcuts to mute drum instruments allow the performer to interact with and control the web-based instrument.</p><p>R-VAE IN MUSICAL PRACTICE<figure><img src=/img/papers/devices-live-set.jpg></figure>The mapping of parameters to control R-VAE and the sound synthesis generation was implemented through three interfaces. The R-VAE decoding from the latent space was controlled through a Kaoss Pad XY grid, potentiometers, and buttons (the device in the middle). The interface of a Tempest synthesizer was used to control the drum sound parameters. Knobs and sliders in a third controller were mapped to the parameters of a physical model synthesizer.</p><p><div class="embed-responsive embed-responsive-16by9"><iframe src="https://www.youtube.com/embed/Kib8Bk2nPEA?enablejsapi=1&color=white&start=200" allowfullscreen></iframe></div>The video shows how the latent spaces is being explored in real-time performance by means of the interaction through the MIDI controllers.</p></div></div></div></div></div></div></div><script src=https://vigliensoni.com/js/jquery.min.js></script>
<script src=https://vigliensoni.com/js/bootstrap.min.js></script>
<script src=https://vigliensoni.com/js/jquery.cookie.js></script><script src=https://vigliensoni.com/js/ekko-lightbox.js></script>
<script src=https://vigliensoni.com/js/jquery.scrollTo.min.js></script>
<script src=https://vigliensoni.com/js/masonry.pkgd.min.js></script>
<script src=https://vigliensoni.com/js/imagesloaded.pkgd.min.js></script>
<script src=https://vigliensoni.com/js/owl.carousel.min.js></script>
<script src=https://vigliensoni.com/js/front.js></script></body></html>